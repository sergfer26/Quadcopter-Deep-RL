# -*- coding: utf-8 -*-
"""supervisado_quadcopter.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yMVHb56fRRCkp245fK0G1zrzCaIhwOSQ

# Quadcopter Supervised Deep-Learning

## Quadcopter Enviorment
"""

'''
!rm -rf Quadcopter-Deep-RL  # in case you need to refresh after pushing changes 
!git clone -b sergio_branch https://github.com/sergfer26/Quadcopter-Deep-RL.git
'''

import torch
import pathlib
import time
import pandas as pd
import numpy as np
import torch.nn as nn
import torch.autograd
import torch.nn.functional as F
import torch.optim as optim

from torch import save
from tqdm import tqdm
from numpy import sin, cos, tan
from numpy.linalg import norm
from matplotlib import pyplot as plt
from scipy.integrate import odeint
from sklearn.preprocessing import StandardScaler

from torch.autograd import Variable
from torch.utils.data import DataLoader, Dataset, random_split

from DDPG.env.quadcopter_env import QuadcopterEnv
from DDPG.utils import NormalizedEnv
from DDPG.models import Actor
from Linear.ecuaciones_drone import imagen2d, f, jac_f
from Linear.step import imagen_accion, step
from DDPG.env.quadcopter_env import funcion, D
import numpy as np

H_SIZES = [18, 64, 64, 64, 64] # dimensión de capas
ACTIONS = 4
BATCH_SIZE = 32
EPOCHS = 100
P = 0.80 # división de datos

net = Actor(H_SIZES, ACTIONS) # función de activación final tan
df = pd.read_csv('tabla_2.csv', header=None)
device = "cpu"

if torch.cuda.is_available(): 
    device = "cuda"
    net.cuda() # para usar el gpu

print(device)
torch.__version__


plt.style.use('ggplot')
dir_ = 'supervisado/'
pathlib.Path(dir_).mkdir(parents=True, exist_ok=True)

env = QuadcopterEnv()
env = NormalizedEnv(env)

def save_net(net, path, name):
    save(net.state_dict(), path+'/'+ name +'.pth')

class CSV_Dataset(Dataset):
    
    def __init__(self, dataframe):
        y = dataframe.iloc[:, 0:4]
        x = dataframe.iloc[:, 4:]
        self.sc_x = StandardScaler()
        x_train = self.sc_x.fit_transform(x)
        y_train = env._reverse_action(y.to_numpy())
        self.x_train = torch.tensor(x_train, dtype=torch.float32)
        self.y_train = torch.tensor(y_train, dtype=torch.float32)
        
    def __len__(self):
        return len(self.y_train)
    
    def __getitem__(self, idx):
        return self.x_train[idx], self.y_train[idx]

"""## From CSV to Dataset"""

dataset = CSV_Dataset(df)
scaler = dataset.sc_x
n_samples = len(df[0])


n_train = int(P * n_samples)
n_val = n_samples - n_train
train_set, val_set = random_split(dataset, [n_train, n_val])

train_loader = DataLoader(train_set, shuffle=True, batch_size=BATCH_SIZE)
val_loader = DataLoader(val_set, shuffle=False, batch_size=BATCH_SIZE)

"""## Training"""

criterion = nn.MSELoss()
optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=0.0005)

def training_loop(train_loader, model, optimizer, loss_function, valid=False):
    running_loss = 0.0
    if valid: 
        model.eval() # modo de validación del modelo 
    for i, data in enumerate(train_loader, 0):
        X, Y = data
        X = X.to(device)
        Y = Y.to(device)
        if not valid:
            optimizer.zero_grad() # reinicia el gradiente
        
        Y_hat = model(X)
        # Y = Y.type(torch.LongTensor) # https://stackoverflow.com/questions/60440292/runtimeerror-expected-scalar-type-long-but-found-float
        # norm_hat = Y_hat.norm(p=2, dim=1, keepdim=True); norm = Y.norm(p=2, dim=1, keepdim=True)
        # Y_hat = Y_hat.div(norm_hat); Y = Y.div(norm)
        real_y_hat = env._action(np.array(Y_hat)); real_y = env._action(np.array(Y))
        real_y_hat = torch.tensor(real_y_hat); real_y = torch.tensor(real_y)
        loss = loss_function(real_y_hat, real_y)
        if not valid:
            loss.backward() # cálcula las derivadas 
            optimizer.step() # paso de optimización 
            
        running_loss += loss.item()
        
        avg_loss = running_loss/(i + 1)
        
    return avg_loss

def train_model(epochs, model, optimizer, train_loader, val_loader, criterion, n_train, n_val):
    train_time = 0
    epoch_loss = []
    val_loss = []

    for _ in range(epochs):
        start_time = time.time()
        loss_train = training_loop(train_loader, model, optimizer, criterion, valid=False)
        train_time +=  time.time() - start_time
        loss_val = training_loop(val_loader, model, None, criterion, valid=True)
        epoch_loss.append(loss_train)
        val_loss.append(loss_val)

    print("--- %s seconds ---", train_time)
    return epoch_loss, val_loss

def plot_loss(epoch_loss, val_loss, show=True, dir_=dir_):
    plt.plot(epoch_loss)
    plt.plot(val_loss)
    plt.title('model loss')
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.legend(['train', 'test'], loc='upper left')
    if show:
        plt.show()
    else:
        plt.savefig(dir_+'/loss.png')

def simulador(Y, T, tam, jac=None):
    '''
    Soluciona el sistema de EDO usando controles en el
    intervalo [0, T].

    param Y: arreglo de la condición inicial del sistema
    param Ze: arreglo de las posiciones estables de los 4 controles
    param T: tiempo final
    param tam: número de elementos de la partición de [0, T]

    regresa; arreglo de la posición final
    '''
    Ze = (15, 0, 0, 0)
    z_e, psi_e, phi_e, theta_e = Ze
    # W0 = np.array([1, 1, 1, 1]).reshape((4, 1)) * omega_0
    X = np.zeros((tam, 12))
    X[0] = Y
    t = np.linspace(0, T, tam)
    acciones = []
    for i in range(len(t)-1):
        [Y_t] = scaler.transform([funcion(Y)]) # transformo la observación a estado de la red

        state = Variable(torch.from_numpy(Y_t).float().unsqueeze(0))
        action = net.forward(state)
        action = action.detach().numpy()[0,:]

        acciones.append(action)
        Y = step(action, Y, [t[i], t[i+1]])[1]
        X[i+1] = Y
    return X, acciones


epoch_loss, val_loss = train_model(EPOCHS, net, optimizer, train_loader, val_loader, criterion, n_train, n_val)
plot_loss(epoch_loss, val_loss, show=False, dir_=dir_)
save_net(net, dir_, 'net')

'''
Y = np.zeros(12); Y[5] = 15
X, acciones = simulador(Y, 30, 800)

z, w, psi, r, phi, p, theta, q = X[:, 5], X[:, 2], X[:, 9], X[:, 8], X[:, 11], X[:, 6], X[:, 10], X[:, 7]
t = np.linspace(0, 30, 800)

imagen2d(z, w, psi, r, phi, p, theta, q, t, show=False, dir_=dir_)
imagen_accion(acciones, t, show=False, dir_=dir_)
'''